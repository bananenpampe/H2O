import numpy as np
from equistore import TensorMap, Labels, TensorBlock
import math

from math import sqrt
from equistore import slice, slice_block
import copy
import torch


# -------- FROM THE EQUISTORE EXAMPLES -----
# CREDIT: PHILIP LOCHE

def einsum(operation, *arrays):
    if isinstance(arrays[0], np.ndarray):
        return np.einsum(operation, *arrays)
    elif isinstance(arrays[0], torch.Tensor):
        return torch.einsum(operation, *arrays)
    else:
        raise ValueError("unknown array type")

def zeros_like(array, shape):
    if isinstance(array, np.ndarray):
        return np.zeros(shape, dtype=array.dtype)
    elif isinstance(array, torch.Tensor):
        return torch.zeros(shape, dtype=array.dtype)
    else:
        raise ValueError("unknown array type")
    
def intersect_2d(a,b):
    set_a = set(map(tuple, a))
    set_b = set(map(tuple, b))

    return np.array(list(set_a & set_b))


"""
def compute_power_spectrum(spherical_expansion_1, spherical_expansion_2=None):
        expected_key_names = [
            "spherical_harmonics_l",
            "species_atom_1",
            "species_atom_2",
        ]
        assert spherical_expansion_1.keys.names == expected_key_names
        assert spherical_expansion_1.property_names == ["n"]
        spherical_expansion_1 = spherical_expansion_1.keys_to_properties(
            "species_atom_2"
        )

        if spherical_expansion_2 is None:
            spherical_expansion_2 = spherical_expansion_1
        else:
            assert spherical_expansion_2.keys.names == expected_key_names
            assert spherical_expansion_2.property_names == ["n"]
            spherical_expansion_2 = spherical_expansion_2.keys_to_properties(
                "species_atom_2"
            )

        blocks = []
        keys = []

        for (ell, species_center), block_1 in spherical_expansion_1.items():
            factor = 1 / sqrt(2 * ell + 1)
            # Find that block indices that have the same spherical_harmonics_l and
            # species_center
            blocks_2 = spherical_expansion_2.blocks(
                spherical_harmonics_l=ell, species_atom_1=species_center
            )
            for block_2 in blocks_2:
                # Makre sure that samples are the same. This should not happen.
                assert block_1.samples == block_2.samples

                properties = Labels(
                    names=["species_neighbor_1", "n1", "species_neighbor_2", "n2"],
                    values=np.array(
                        [
                            properties_1.tolist() + properties_2.tolist()
                            for properties_1 in block_1.properties.values
                            for properties_2 in block_2.properties.values
                        ],
                        dtype=np.int32,
                    ),
                )

                # Compute the invariants by summation and store the results this is
                # equivalent to an einsum with: ima, imb -> iab
                data = factor * np.matmul(block_1.values.swapaxes(1, 2), block_2.values)

                new_block = TensorBlock(
                    values=data.reshape(data.shape[0], -1),
                    samples=block_1.samples,
                    components=[],
                    properties=properties,
                )

                keys.append((ell, species_center))
                blocks.append(new_block)

        keys = Labels(
            names=["l", "species_center"],
            values=np.array(keys, dtype=np.int32),
        )

        return TensorMap(keys, blocks).keys_to_properties("l")
"""

def compute_power_spectrum(spherical_expansion_1, spherical_expansion_2=None, naming_convention="pair"):
    """
    Starting from spherical expansion coefficients obtained from an
    external code (e.g. rascaline or also librascal/pyLODE after converting
    to the proper storage format) generate the rotationally invariant
    power spectrum.
    Returns:
    --------
    A Descriptor object containing the invariant features and all its
    associated labels.
    """
    # Make sure that the expansion coefficients have the correct set of keys
    # associated with 1-center expansion coefficients.
    if naming_convention == "pair":
        assert spherical_expansion_1.keys.names == [
            "spherical_harmonics_l",
            "species_atom_1",
            "species_atom_2",
        ]
    elif naming_convention == "soap":
         assert spherical_expansion_1.keys.names == [
            "spherical_harmonics_l",
            "species_center",
            "species_neighbor",
         ]
    else:
        assert False       

    # If two different sets of coefficients are provided, it is assumed
    # that the invariants are generated by taking quadratic combinations
    # of those.
    # Otherwise, invariants are generated by combining coefficients from
    # two different calculators.
    if spherical_expansion_2 is None:
        use_same_spherical_expansions = True
        spherical_expansion_2 = copy.deepcopy(spherical_expansion_1)
    else:
        use_same_spherical_expansions = False
        if naming_convention == "pair":
            assert spherical_expansion_1.keys.names == [
                "spherical_harmonics_l",
                "species_atom_1",
                "species_atom_2",
            ]
        elif naming_convention == "soap":
            assert spherical_expansion_1.keys.names == [
                "spherical_harmonics_l",
                "species_center",
                "species_neighbor",
            ]
        else:
            assert False 

    blocks = []
    keys = []

    for (l1, cs1, ns1), spx_1 in list(spherical_expansion_1.items()):
        for (l2, cs2, ns2), spx_2 in list(spherical_expansion_2.items()):
            if l1 != l2 or cs1 != cs2:
                continue
            
            spx_1_i = copy.deepcopy(spx_1)
            spx_2_i = copy.deepcopy(spx_2)

            # Find common samples if samples are not the same
            if not np.all(spx_1.samples == spx_2.samples):
                val_pairs = intersect_2d(np.array(spx_1.samples), np.array(spx_2.samples))

                if val_pairs.shape[0] == 0:
                    #print("l1:{},cs1:{},ns1:{},l2:{},cs2:{},ns2:{}".format(l1,cs1,ns1,l2,cs2,ns2))

                    #print(np.array(spx_1.samples))
                    #print(np.array(spx_2.samples))
                    #print("skipping block: {} {} {}".format(cs1,cs2,ns1))
                    continue

                common_samples = Labels(
                    names=spx_1.samples.names,
                    values=val_pairs)


                spx_1_i = slice_block(copy.deepcopy(spx_1), labels=common_samples, axis="samples")
                spx_2_i = slice_block(copy.deepcopy(spx_2), labels=common_samples, axis="samples")

            # Avoid doubly computing / storing invariants that are
            # the same by symmetry of the neighbor species.
            # Example: Neighbor species (Na, Cl) produces the same
            # invariants as (Cl, Na), meaning that only one set
            # of invariants needs to be used.
            # If the two sets of expansion coefficients are different,
            # this does not apply
            if ns1 > ns2 and use_same_spherical_expansions:
                continue
                #factor = sqrt(2) / sqrt(2 * l1 + 1)
            elif ns1 == ns2:
                factor = 1.0 / sqrt(2 * l1 + 1)
            else:
                factor = sqrt(2) / sqrt(2 * l1 + 1)

            properties = Labels(
                names=[f"{name}_1" for name in spx_1_i.properties.names]
                + [f"{name}_2" for name in spx_2_i.properties.names],
                values=np.array(
                    [
                        np.array(properties_1).tolist() + np.array(properties_2).tolist()
                        for properties_1 in spx_1_i.properties
                        for properties_2 in spx_2_i.properties
                    ],
                    dtype=np.int32,
                ),
            )

            # Compute the invariants by summation and store the results
            #print(spx_1.values), print(spx_2.values)

            data = factor * einsum("ima, imb -> iab", spx_1_i.values, spx_2_i.values)

            block = TensorBlock(
                values=data.reshape(data.shape[0], -1), #.to(torch.device("cpu")).contiguous(),
                samples=spx_1_i.samples,
                components=[],
                properties=properties,
            )

            n_properties = block.values.shape[1]

            if spx_1_i.has_gradient("positions"):
                gradient_1 = spx_1_i.gradient("positions")
                gradient_2 = spx_2_i.gradient("positions")

                if len(gradient_1.samples) == 0 or len(gradient_2.samples) == 0:
                    continue

                gradients_samples = np.unique(
                    np.concatenate([gradient_1.samples, gradient_2.samples])
                )
                gradients_samples = gradients_samples.view(np.int32).reshape(-1, 3)

                gradients_samples = Labels(
                    names=gradient_1.samples.names, values=gradients_samples
                )

                gradients_sample_mapping = {
                    tuple(sample): i for i, sample in enumerate(gradients_samples)
                }

                gradient_data = zeros_like(
                    gradient_1.data, (gradients_samples.shape[0], 3, n_properties)
                )

                gradient_data_1 = factor * einsum(
                    "ixma, imb -> ixab",
                    gradient_1.data,
                    spx_2_i.values[gradient_1.samples["sample"], :, :],
                ).reshape(gradient_1.samples.shape[0], 3, -1)

                for sample, row in zip(gradient_1.samples, gradient_data_1):
                    new_row = gradients_sample_mapping[tuple(sample)]
                    gradient_data[new_row, :, :] += row

                gradient_data_2 = factor * einsum(
                    "ima, ixmb -> ixab",
                    spx_1_i.values[gradient_2.samples["sample"], :, :],
                    gradient_2.data,
                ).reshape(gradient_2.samples.shape[0], 3, -1)

                for sample, row in zip(gradient_2.samples, gradient_data_2):
                    new_row = gradients_sample_mapping[tuple(sample)]
                    gradient_data[new_row, :, :] += row

                assert gradient_1.components[0].names == ("direction",)
                block.add_gradient(
                    "positions",
                    gradient_data, #.to(torch.device("cpu")).contiguous(),
                    gradients_samples,
                    [gradient_1.components[0]],
                )

            keys.append((l1, cs1, ns1, ns2))
            blocks.append(block)

    keys = Labels(
        names=[
            "spherical_harmonics_l",
            "species_center",
            "species_neighbor_1",
            "species_neighbor_2",
        ],
        values=np.array(keys, dtype=np.int32),
    )
    descriptor = TensorMap(keys, blocks)
    descriptor = descriptor.keys_to_properties("spherical_harmonics_l")
    return descriptor